{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from uk_covid19 import Cov19API\n",
    "\n",
    "min_confirmed = 5\n",
    "days_ran = 250\n",
    "days_predicted = 20\n",
    "\n",
    "\n",
    "class LoadData:\n",
    "    @staticmethod\n",
    "    def getUkdf() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        get the data from Nhs api\n",
    "        These should return a dataframe\n",
    "        \"\"\"\n",
    "\n",
    "        all_nations = [\"areaType=utla\"]\n",
    "\n",
    "        cases_and_deaths = {\n",
    "            \"date\": \"date\",\n",
    "            \"areaName\": \"areaName\",\n",
    "            \"dailyCases\": \"newCasesByPublishDate\",\n",
    "            \"dailyDeaths\": \"newDeaths28DaysByPublishDate\",\n",
    "            \"cumulativeCases\": \"cumCasesByPublishDate\",\n",
    "        }\n",
    "\n",
    "        api = Cov19API(filters=all_nations, structure=cases_and_deaths)\n",
    "\n",
    "        df = api.get_dataframe()\n",
    "\n",
    "        # df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "        # df_uk = df[df.daily > min_confirmed]\n",
    "        # df_uk[\"day\"] = df_uk.date.apply(\n",
    "        #     lambda x: (x-df_uk.date.min()).days\n",
    "        # )\n",
    "        # df_uk = df_uk.reset_index()\n",
    "\n",
    "        # if retain == True:\n",
    "        #     lastdate = str(df_uk.date.iloc[-1])\n",
    "        #     df_uk.to_csv(lastdate + \"_uk_by_day.csv\", index=False)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "        df.fillna(\n",
    "            value={\"dailyDeaths\": 0, \"cumulativeCases\": 0},\n",
    "            inplace=True,\n",
    "            downcast=\"int64\",\n",
    "        )\n",
    "        df = df[df.dailyCases > min_confirmed]\n",
    "        df[\"day\"] = df.date.apply(lambda x: (x - df.date.min()).days)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def getcitiesDF(df: pd.DataFrame, city_name: str) -> pd.DataFrame:\n",
    "        \"\"\"[Get updated data on the epidemic of a specific city by day in the uk]\n",
    "        Args:\n",
    "            df ([type: datframe]): [The resulting Data returned from the covid19 uk data api]\n",
    "            city_name (str): [the name of the city that should be passed]\n",
    "        Returns:\n",
    "            pd.DataFrame: [covid-19 cumulative data of daily confirmed and death in the uk for a particular city]\n",
    "        \"\"\"\n",
    "\n",
    "        grouped_area = df[df[\"areaName\"] == city_name]\n",
    "        grouped_area_cases = grouped_area.drop(columns=[\"areaName\"])\n",
    "        grouped_area_cases = grouped_area_cases.reset_index(drop=True)\n",
    "        new_df = grouped_area_cases.head(days_ran)\n",
    "\n",
    "        time_data = np.array(new_df.day.values.astype(np.float64))\n",
    "        time_data = time_data - time_data[0]\n",
    "\n",
    "        dailycases = new_df.dailyCases.values.astype(np.float64)\n",
    "        deathcases = np.diff(new_df.dailyDeaths.values.astype(np.float64))\n",
    "        deathcases = np.insert(deathcases, 0, deathcases[0])\n",
    "\n",
    "        original_data = np.array([dailycases, deathcases])\n",
    "\n",
    "        data_dates = new_df.date.values\n",
    "        data_dates = [date.strftime(\"%d/%m/%y\") for date in data_dates]\n",
    "\n",
    "        return original_data, data_dates, time_data\n",
    "\n",
    "    @staticmethod\n",
    "    def getDataJH() -> pd.DataFrame:\n",
    "        # https://gradcoach.com/literature-review-structure/\n",
    "\n",
    "        confirmed_df = pd.read_csv(\n",
    "            \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "        )\n",
    "        deaths_df = pd.read_csv(\n",
    "            \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
    "        )\n",
    "        recoveries_df = pd.read_csv(\n",
    "            \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\"\n",
    "        )\n",
    "        # latest_data = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/08-22-2020.csv')\n",
    "        # us_medical_data = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/08-22-2020.csv')\n",
    "\n",
    "        # data_url = requests.get(url).content\n",
    "        # df = pd.read_csv(io.StringIO(data_url.decode(\"utf-8\")))\n",
    "\n",
    "        # confirmed_df = confirmed_df.drop(\n",
    "        #     [\"UID\", \"iso2\", \"iso3\", \"code3\", \"FIPS\", \"Admin2\", \"Combined_Key\"], axis=1\n",
    "        # )\n",
    "        # deaths_df = deaths_df.drop(\n",
    "        #     [\"UID\", \"iso2\", \"iso3\", \"code3\", \"FIPS\", \"Admin2\", \"Combined_Key\"], axis=1\n",
    "        # )\n",
    "        # recoveries_df = recoveries_df.drop(\n",
    "        #     [\"UID\", \"iso2\", \"iso3\", \"code3\", \"FIPS\", \"Admin2\", \"Combined_Key\"], axis=1\n",
    "        # )\n",
    "\n",
    "        columns_rename = {\"Province_State\": \"State\", \"Country_Region\": \"Country\"}\n",
    "        confirmed_df.rename(columns=columns_rename, inplace=True)\n",
    "        deaths_df.rename(columns=columns_rename, inplace=True)\n",
    "        recoveries_df.rename(columns=columns_rename, inplace=True)\n",
    "\n",
    "        confirmed_df = confirmed_df.groupby(by=\"Country\", as_index=False).sum()\n",
    "        deaths_df = deaths_df.groupby(by=\"Country\", as_index=False).sum()\n",
    "        recoveries_df = recoveries_df.groupby(by=\"Country\", as_index=False).sum()\n",
    "\n",
    "        grouped_df = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"date\",\n",
    "                \"State\",\n",
    "                \"Country\",\n",
    "                \"Lat\",\n",
    "                \"Long\",\n",
    "                \"Confirmed\",\n",
    "                \"Deaths\",\n",
    "                \"Recorvered\",\n",
    "            ]\n",
    "        )\n",
    "        grouped_df[\"date\"] = confirmed_df.columns[4:]\n",
    "        grouped_df[\"Confirmed\"] = grouped_df[\"Dates\"].apply(\n",
    "            lambda x: confirmed_df[x].sum()\n",
    "        )\n",
    "        grouped_df[\"Deaths\"] = grouped_df[\"Dates\"].apply(lambda x: deaths_df[x].sum())\n",
    "        grouped_df[\"Recovered\"] = grouped_df[\"Dates\"].apply(\n",
    "            lambda x: recoveries_df[x].sum()\n",
    "        )\n",
    "        grouped_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 6, saw 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://population.un.org/wpp/Download/Standard/CSV/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m df_pop \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(url \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mWPP2019_PopulationByAgeSex_Medium.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m df_pop \u001b[39m=\u001b[39m df_pop[(df_pop[\u001b[39m'\u001b[39m\u001b[39mVariant\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMedium\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m&\u001b[39m\n\u001b[0;32m      8\u001b[0m                 (df_pop[\u001b[39m'\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m2020\u001b[39m) \u001b[39m&\u001b[39m\n\u001b[0;32m      9\u001b[0m                 (df_pop[\u001b[39m'\u001b[39m\u001b[39mLocation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mWorld\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m     10\u001b[0m df_pop \u001b[39m=\u001b[39m df_pop[[\u001b[39m'\u001b[39m\u001b[39mLocation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAgeGrp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPopMale\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPopFemale\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\Documents\\GitHub\\covid-19-forcasting-experiments\\.conda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 6, saw 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'https://population.un.org/wpp/Download/Standard/CSV/'\n",
    "df_pop = pd.read_csv(url + 'WPP2019_PopulationByAgeSex_Medium.csv')\n",
    "df_pop = df_pop[(df_pop['Variant'] == 'Medium') &\n",
    "                (df_pop['Time'] == 2020) &\n",
    "                (df_pop['Location'] != 'World')]\n",
    "df_pop = df_pop[['Location', 'AgeGrp', 'PopMale', 'PopFemale']]\n",
    "df_pop = df_pop.rename(columns={'PopMale': 'Male', 'PopFemale': 'Female'})\n",
    "df_pop['Total'] = df_pop['Male'] + df_pop['Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# Define a function to extract risk level data from JSON files\n",
    "def extract_risk_level(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    risk_level = None\n",
    "    for entry in data['metadata']['clinical_trials']:\n",
    "        if entry['primary_outcome'] == 'Participant Mortality':\n",
    "            risk_level = entry['recruitment_details']['eligibility_criteria'][0]['value']\n",
    "    return risk_level\n",
    "\n",
    "# Define a function to extract location from JSON files\n",
    "def extract_location(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    location = None\n",
    "    for entry in data['metadata']['clinical_trials']:\n",
    "        if entry['primary_outcome'] == 'Participant Mortality':\n",
    "            location = entry['location_countries'][0]['country']\n",
    "    return location\n",
    "\n",
    "json_files = glob.glob('cord19/**/*.json', recursive=True)\n",
    "risk_levels = []\n",
    "locations = []\n",
    "for json_file in json_files:\n",
    "    risk_level = extract_risk_level(json_file)\n",
    "    location = extract_location(json_file)\n",
    "    if risk_level is not None and location is not None:\n",
    "        risk_levels.append(float(risk_level))\n",
    "        locations.append(location)\n",
    "\n",
    "df_risk = pd.DataFrame({'Location': locations, 'RiskLevel': risk_levels})\n",
    "df_risk = df_risk.groupby('Location').mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>RiskLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Location, RiskLevel]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_pop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_pop\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_pop' is not defined"
     ]
    }
   ],
   "source": [
    "df_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 3) (2433553967.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    df_vaccine = df_vaccine[df_vaccine['Vaccine'] == 'Pfizer/Bio\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 3)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://covid19.who.int/who-data/vaccination-data.csv'\n",
    "df_vaccine = pd.read_csv(url, usecols=['ISO3', 'Vaccine', 'Doses_Admin', 'Doses_Req', 'Efficacy'])\n",
    "df_vaccine = df_vaccine[df_vaccine['Vaccine'] == 'Pfizer/Bio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
